* Fediverse social graph

This is the final project for my degree in Applied Data Science. In it, I programmed a scrapper that visits /Fediverse/ users and stores their /followers/ and /following/ collections, if allowed, in a Neo4j graph database.

** User scraper

The scraper [[https://github.com/pecuchetian/tfg/blob/main/users_scrape.py][users_scrape.py]] is installed as a /systemd/ unit and works autonomously, even though it requires frequent restarting. It is multithreaded and makes use of a [[https://github.com/pecuchetian/tfg/blob/main/queries/db.py][Db]] and [[https://github.com/pecuchetian/tfg/blob/main/queries/user.py][User]] classes.

** Data

The data obtained has been stored in a Neo4J database. Some exploratory analysis has been made in [[https://github.com/pecuchetian/tfg/blob/main/GraphQueries.ipynb][GraphQueries.ipynb]].

** Bot

The scripts [[https://github.com/pecuchetian/tfg/blob/main/bot.py][bot.py]] and [[https://github.com/pecuchetian/tfg/blob/main/recomend_bot.py][recomend_bot.py]] update a /Mastodon/ bot account and reply to requests for similar users. Try them at https://mastodon.eugasser.com/@botbot.

* Usage

** Secrets

We use the dotenv Python library with a .env file where sensitive info is stored. This file is included in .gitignore.

** Connections

#+begin_src bash


  # connect to my hetzner instance

  ssh pecuchet@[your-server-address] -i .ssh/id_ed25519

  # connect with neo4j and jupyter tunnels


  ssh -N -L 8888:[your-server-address]:8888 -L 7474:[your-server-address]:7474 -L 7687:[your-server-address]:7687  [your-server-address]  -i ~/.ssh/id_ed25519

#+end_src


** Python and jupyter

*** Create venv and install jupyter in it
#+begin_src bash


cd /home/pecuchet/UOC

python3 -m venv tfg-venv

source tfg-venv/bin/activate

# python3 -m pip install jupyter

jupyter lab

#+end_src

Start jupyter like this.

#+begin_src bash

Have this script ready
# start_tfg_jupyter
source /home/pecuchet/UOC/tfg-venv/bin/activate

nohup jupyter lab &

#+end_src



REMOTE jupyter without ssh tunnel [instructions here](https://dbusteed.github.io/setup-jupyter-lab-on-remote-server/ "instructions").

Access on local machine [http://[your-server-address]:8000/lab](http://[your-server-address]:8000/lab).


** Neo4j

Access _Neo4j Browser_ on the server with a ssh tunnel with your local machine.

#+begin_src bash

# use sudo for restarting neo4j

cypher-shell

# usr neo4j pw [password]

# ssh tunnel for browser

ssh -N -L 7474:[your-server-address]:7474 -L 7687:[your-server-address]:7687  [your-server-address]  -i ~/.ssh/id_ed25519

# visit on local machine http://localhost:7474/browser/

#+end_src

*** Data model 

A sample user and server would be:

#+begin_src json
User: {
  "identity": 0,
  "labels": [
    "User"
  ],
  "properties": {
    "server": "https://mastodon.eugasser.com",
    "followers": 11,
    "following": 62,
    "name": "pecuchet",
    "uri": "https://mastodon.eugasser.com/users/pecuchet"
  },
  "elementId": "0"
}

Server : {
  "identity": 3856,
  "labels": [
    "Server"
  ],
  "properties": {
    "url": "https://mastodon.eugasser.com"
  },
  "elementId": "3856"
}

#+end_src

We have the following relationships.

#+begin_src cypher

(:User)-[:FOLLOWS]->(:User)

(:User)-[:IN_COMUNITY]->(:Server)

(:User)-[:SCRAPED_ON]->(:Round)  

#+end_src


*** Neo4j OOM issue

Neo4j service fails (is terminated) by the system every 20h because it eats up all the memory. 


* Moving ahead / possible improvements

** Data Model

The relationship =[:SCRAPED_ON]= is useful to track which nodes have been completed, but not for next rounds. If you want to start another scraping round, you need an attribute on the =[:FOLLOWS]= relationship.

** Unscraped nodes query

When getting unscraped from the database the query is too slow:

#+begin_src cypher
  
WITH $this_round as this_round
MATCH (u:User)-[f:SCRAPED_ON]->(r:Round WHERE r.id < this_round)
RETURN u.uri as uri
ORDER  BY r  LIMIT 500
UNION ALL
MATCH (u:User) WHERE NOT (u)-[]->(:Round)
RETURN u.uri as uri
LIMIT 500

  
#+end_src

Instead of this, try a random walk. Start with a random user with no [:SCRAPED_ON] relationship and query 500 times for users with this condition. Another option would be to project all users with this condition (possibly too slow, but can be done sparingly, just keep the projection for a few times), select randomly and then search for user's uri back in the database.

* State of things/ TODOS

***** DONE SOLVE DUPLICATE ENTRIES IN Db
CLOSED: [2023-11-02 Thu 13:57]
***** PARALLELIZE [3/4]:
****** DONE Queue object is SetQueue. Allows control of duplicates.
CLOSED: [2023-11-21 Tue 11:34]
****** DONE Clean users.py and implement mastodon api usage on 401 response on AP endpoint
CLOSED: [2023-11-21 Tue 11:34]
****** DONE Implement some sort of max retries/endless loop control
****** DONE Implement a done attribute in neo4j as a FINISHED_ON relationship. Create Nodes of type :Timestamp with a timestamp attribute
CLOSED: [2023-11-21 Tue 11:34]
******* DONE relationship is (:User)-[SCRAPED_ON]->(:Round) where Round has attributes Round.id = 1, 2, 3 and Round.started_on, Round.finished_on timestamp().
CLOSED: [2023-11-09 Thu 11:00]
******* DONE Mark (:User) as scraped when we receive non 200 response or 0 friends. Call verify_friend_count or something.
CLOSED: [2023-11-21 Tue 11:35]
***** TODO Fix request response bugs
***** TODO Improve general scrape speed. Consistency of worker thread number.
***** TODO Neo4j hangs every 24 hours. Find out why and fix.

